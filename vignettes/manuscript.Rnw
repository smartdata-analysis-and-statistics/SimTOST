\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{orcidlink,thumbpdf,lmodern}

%% sideways tables
%\usepackage{rotating}


%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

%% For Sweave-based articles about R packages:
%% need no \usepackage{Sweave}
\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<preliminaries, echo=FALSE, results=hide>>=
options(prompt = "R> ", continue = "+  ", width = 70, useFancyQuotes = FALSE)
library("MASS")
@


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation (and optionally ORCID link)
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Thomas Debray~\orcidlink{0000-0002-1790-2719}\\Smart Data Analysis and Statistics
   \And Johanna Munoz\\Smart Data Analysis and Statistics \AND Scott McDonald\\Smart Data Analysis and Statistics \And Marian Mitriou\\Biogen \AND Wei Wei\\Biogen}
\Plainauthor{Thomas Debray, Johanna Munoz, Scott McDonald, Marian Mitroiu, Wei Wei}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{Sample size estimation for bioequivalence trials through simulation: the SimTOST \proglang{R} package }
\Plaintitle{Sample size estimation for bioequivalence trials through simulation: the SimTOST R package}
\Shorttitle{An introduction to SimTOST}

%% - \Abstract{} almost as usual
\Abstract{
  Sample size estimation for clinical trials is challenging when hypothesis tests involve comparisons across multiple endpoints and/or treatments. This situation commonly arises in biosimilar trials, where pharmacokinetic parameters of interest, bioequivalence criteria and reference products may differ between regulatory bodies. This paper presents the \pkg{SimTOST} \proglang{R} package to facilitate sample size estimation for Phase 1 randomized bioequivalence trials that investigate multiple hypotheses, treatments, and correlated endpoints. Unlike deterministic approaches commonly used in existing \proglang{R} packages and sample size software, \pkg{SimTOST} uses a simulation-based approach, which enables researchers to address the complexities of evaluating multiple hypotheses across diverse (co-)primary endpoints. Several parameters can be configured, including the number of arms, the size of each arm, distributional assumptions, multiplicity corrections, selection and integration of hypothesis tests, and drop-out. Using an example dataset, we illustrate the use of \pkg{SimTOST} for calculating the sample size for a complex, yet frequently encountered situation: three arms, three co-primary endpoints with correlation, and two regulatory settings with distinct reference products.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{sample size, simulation, bioequivalence, biosimilar trials, Monte Carlo simulation, Two-One-Sided Test, clinical trial design, \proglang{R}}
\Plainkeywords{sample size, simulation, bioequivalence, biosimilar trials, Monte Carlo simulation, Two-One-Sided Test, clinical trial design, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Thomas Debray\\
  Smart Data Analysis and Statistics\\
  3524HM Utrecht, The Netherlands\\
  E-mail: \email{tdebray@fromdatatowisdom.com}\\
  URL: \url{https://www.fromdatatowisdom.com/}
}

\begin{document}
%\SweaveOpts{concordance=TRUE}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section[Introduction]{Introduction} \label{sec:intro}

Sample size estimation is a critical aspect of clinical trial design, as it ensures sufficient statistical power to detect meaningful effects while minimizing unnecessary resource use and participant burden. However, sample size estimation becomes particularly complex when multiple endpoints, treatments, and hypotheses are involved. These challenges are frequently encountered in bioequivalence trials, for which pharmacokinetic parameters, bioequivalence criteria, and reference products often vary across regulatory bodies.

Existing software solutions, both simple and advanced, often fall short of addressing the intricacies of bioequivalence trial designs.  Generic sample size packages, such as the \proglang{R} package \pkg{pwr} \citep{Champely2020} provide basic power calculations for tests involving proportions, means, one-way ANOVA, and the general linear model, as well as effect size computation. However, these packages are restricted to trials with simple designs, typically involving two arms and a single endpoint. Similarly, \pkg{TrialSize} \citep{TrialSize2020} which offers over 80 functions for clinical trial sample size estimation, lacks the specialized features required for handling more advanced biosimilar trial scenarios.

More advanced packages, such as \pkg{rpact} \citep{rpact2024}, are tailored for adaptive clinical trials and support complex designs, including group-sequential and multi-arm trials. However, these tools are not specifically designed to address the unique challenges of bioequivalence studies, such as implementing equivalence-specific statistical methodologies.

Specialized \proglang{R} packages like \pkg{PowerTOST} \citep{PowerTOST2024} and \pkg{TOSTER} \citep{Caldwell2022} focus specifically on equivalence testing, with a strong emphasis on the TOST procedure (two one-sided t-tests). These packages provide robust support for standard bioequivalence trials but are limited in their capacity to handle more complex designs, such as those involving multiple arms or more intricate statistical frameworks.

Proprietary software such as nQuery \citep{nQuery2024} and PASS \citep{PASS2024} offers broader capabilities. For instance, nQuery supports a range of adaptive, group-sequential, and fixed sample size trials, including some bioequivalence study designs, such as the 2x2 crossover design. Similarly, PASS includes procedures for biosimilar trials using a parallel 2-group design. However, their applicability to more complex trial scenarios remains limited, and the reliance on proprietary systems may hinder reproducibility and accessibility. A summary of the existing R packages and other applicable software is provided in Table~\ref{tab:overview}.

\begin{table}[t!]
\centering
\begin{tabular}{lp{2.0cm}p{4.7cm}p{3.6cm}}
\hline
Software         & Domain of focus & Features   & Limitations \\
 & & & \\\hline
\pkg{PowerTOST}           & Biosimilar trials      & Wide range of power and sample size functions for (bio)equivalence studies & Limited support for trials with more than two arms\\
\pkg{TOSTER} &  Biosimilar trials   & Focuses on two one-sided tests (TOST) with functions for equivalence testing and minimal effects testing  & Limited support for trials with more than two arms\\
\pkg{rpact}  &  Adaptive trials & Comprehensive power and sample size functions for various endpoints in adaptive trials & No specific focus on biosimilar studies\\
\pkg{pwr}     & Generic power calculations           &   Basic power calculations for proportions, means, and simple statistical tests & Restricted to relatively simple trial designs \\
\pkg{TrialSize} & Clinical trials      & Extensive sample size functions for diverse clinical trial designs, including dose escalation studies & No specific focus on biosimilar studies\\\hline
PASS & Clinical trials and other designs  & Extensive power and sample size procedures for a variety of study designs & Proprietary software; limited functionality for biosimilar designs \\
nQuery	& Adaptive trials &	Comprehensive power and sample size functionality, including frequentist and Bayesian methods & Proprietary software \\ \hline
\end{tabular}
\caption{\label{tab:overview} R packages and other software for sample size calculation for bio-equivalence trials}
\end{table}

This paper presents the \proglang{R} package \pkg{SimTOST}, which is intended for use by clinical trial statisticians with a basic understanding of \proglang{R}, clinical trial design, and sample size calculation. \pkg{SimTOST} was developed to streamline sample size estimation for Phase 1 randomized bioequivalence trials. Major features of the software include the evaluation of multiple treatment arms, evaluation of multiple (co-)primary endpoints, configuration of distributional assumptions, customization of trial success criteria, adjustment for multiplicity, and empirical assessment of power and the type I error rate. Unlike conventional methods, \pkg{SimTOST} addresses the particular complexities of biosimilar trials, in that it can deal appropriately with multiple hypotheses, treatments, and correlated endpoints with flexibility and accuracy. We are not aware of any existing software/\proglang{R} package that is aimed specifically at sample size estimation for bioequivalence trials, that can also handle multiple endpoints, testing of multiple hypotheses, and crossover designs.

The rest of this paper is structured as follows: Section~\ref{sec:bioequivalence} reviews the distinguishing features of biosimilar trials and summarises the key methods developed for sample size estimation for bioequivalence studies. In Section~\ref{sec:pkgSimTOST}, the principal functionality of the \pkg{SimTOST} package is presented. In Section 4, several advanced features of the package are described, including multiple hypothesis testing. Section 5 presents a worked example to illustrate application of the software to a complex, but real-world situation encountered in the bioequivalence field: trials with three arms, three correlated co-primary endpoints, and two different reference products. Finally, Section 6 provides discussion, future directions, and conclusions.

\section{Bioequivalence} \label{sec:bioequivalence}

\subsection{Biosimilar versus conventional trial designs}
When two formulations of the same drug or two drug products are claimed to be bioequivalent, it is assumed that they provide the same therapeutic effect, are therapeutically equivalent, and can be used interchangeably. Bioequivalence is a critical concept in biosimilar trials, as it establishes that the new product performs similarly to a reference product in terms of efficacy and safety.

Biosimilar trials differ from conventional clinical trials in both their objectives and their choice of comparator arms. While conventional trials typically aim to establish superiority or non-inferiority, the primary goal of a biosimilar trial is to demonstrate (bio)equivalence. Additionally, the comparator in a biosimilar trial is a reference medicinal product —- a previously approved drug —- rather than the standard of care, placebo, sham, or other alternatives commonly used in conventional trials.

Two medicinal products are considered bioequivalent if they meet specific criteria. These products must be either:

\begin{itemize}
  \item Pharmaceutical equivalents: Products that differ only in manufacturer but are otherwise identical in active ingredients, strength, and dosage form.
	\item Pharmaceutical alternatives: Products that differ in their dosage form or formulation but contain the same active ingredients.
\end{itemize}

Bioequivalence is determined by comparing the bioavailability of the two products, which involves assessing the rate and extent of drug absorption using a standard set of pharmacokinetic parameters. The products are deemed bioequivalent if their bioavailability falls within predefined limits set by regulatory guidelines. \citep{CHMP2010}

Unlike conventional trials, biosimilar trials may involve more than one reference product. This situation arises when different regulatory bodies stipulate distinct reference products for the clinical indication of interest. In such cases, it may be desirable to design a single trial that addresses the requirements of multiple regulators by simultaneously comparing the new product to two reference products. Estimating the sample size for such a trial requires careful consideration of the trial’s unique design and objectives.

Figure~\ref{fig:exampletrial} illustrates an example of this approach, where a new treatment is compared to two different reference treatments across three outcomes, meeting the diverse requirements of multiple regulatory authorities.

\begin{figure}[t!]
\centering
\includegraphics[width=\textwidth]{fig_manuscript_01.png}
\caption{\label{fig:exampletrial} Example trial illustrating comparisons for three outcomes (AUCInf, AUClast, and Cmax) between a new treatment and reference products designated by different regulatory bodies (USA and EU).}
\end{figure}

\subsection{Bioequivalence studies: key methodological considerations}
Designing and analyzing a bioequivalence study requires careful attention to two critical methodological aspects: (i) the measurement of pharmacokinetic parameters, which serve as the primary outcomes for comparing treatments; and (ii) the statistical methods used to evaluate and compare these outcomes.

The selection of pharmacokinetic (PK) parameters to estimate depends on trial characteristics, such as the sampling period. As outlined by \cite{CHMP2010}, in biosimilar studies aiming to demonstrate bioequivalence after a single dose, the actual sampling times should be utilized, and the following PK parameters should be evaluated:

\begin{itemize}
\item AUCInf (Area Under the Curve to Infinity): Total drug exposure over time, including extrapolated data beyond the last measurable concentration.
\item AUClast (Area Under the Curve to Last Time Point): Drug exposure calculated up to the last measurable concentration.
\item Cmax (Maximum Concentration): Peak plasma concentration, reflecting the highest level of drug exposure.
\item Residual Area: The proportion of AUC that is extrapolated beyond the observed data, providing insight into the elimination phase.
\item tmax (Time to Maximum Concentration): The time taken to reach the peak plasma concentration, indicating the rate of absorption.
\end{itemize}

For biosimilar trials, equivalence testing methods are required when the objective of a statistical test is to demonstrate that the size of a difference in an endpoint of interest between two (or more) trial arms is not meaningful (i.e., not clinically relevant). For the base case of evaluating whether a new pharmaceutical product is `equivalent' to the reference product, the Two One-Sided Tests (TOST) procedure is deployed, in which the null hypothesis of `new product is worse by a clinically relevant amount' is compared with the alternative hypothesis of `difference between products is too small to be clinically relevant' \citep{schuirmann_comparison_1987, shieh_assessing_2022}.

The TOST procedure involves evaluating two one-sided hypotheses to assess equivalence. The first null hypothesis is defined as:
%
\begin{equation} \label{eq:TOST_01}
H_{01}: \mu_T - \mu_R \leq \theta_1,
\end{equation}
%
with its corresponding alternative hypothesis:
%
\begin{equation} \label{eq:TOST_11}
H_{11}: \mu_T - \mu_R > \theta_1.
\end{equation}
%

Similarly, the second null hypothesis is defined as:
%
\begin{equation} \label{eq:TOST_01}
H_{02}: \mu_T - \mu_R \geq \theta_2,
\end{equation}
%
with its corresponding alternative hypothesis:
%
\begin{equation} \label{eq:TOST_11}
H_{12}: \mu_T - \mu_R < \theta_2.
\end{equation}
%
Equivalence between $\mu_T$ and $\mu_R$ is established, if and only if, both $H_{01}$ and $H_{02}$ are rejected at the chosen significance level $\alpha$.

\section{The SimTOST package} \label{sec:pkgSimTOST}




\begin{leftbar}
The introduction is in principle ``as usual''. However, it should usually embed
both the implemented \emph{methods} and the \emph{software} into the respective
relevant literature. For the latter both competing and complementary software
should be discussed (within the same software environment and beyond), bringing
out relative (dis)advantages. All software mentioned should be properly
\verb|\cite{}|d. (See also Appendix~\ref{app:bibtex} for more details on
\textsc{Bib}{\TeX}.)

For writing about software JSS requires authors to use the markup
\verb|\proglang{}| (programming languages and large programmable systems),
\verb|\pkg{}| (software packages), \verb|\code{}| (functions, commands,
arguments, etc.). If there is such markup in (sub)section titles (as above), a
plain text version has to be provided in the {\LaTeX} command as well. Below we
also illustrate how abbrevations should be introduced and citation commands can
be employed. See the {\LaTeX} code for more details.
\end{leftbar}

Modeling count variables is a common task in economics and the social sciences.
The classical Poisson regression model for count data is often of limited use in
these disciplines because empirical count data sets typically exhibit
overdispersion and/or an excess number of zeros. The former issue can be
addressed by extending  the plain Poisson regression model in various
directions: e.g., using sandwich covariances or estimating an additional
dispersion parameter (in a so-called quasi-Poisson model). Another more formal
way is to use a negative binomial (NB) regression. All of these models belong to
the family of generalized linear models (GLMs). However, although these models
typically can capture overdispersion rather well, they are in many applications
not sufficient for  modeling excess zeros. Since \cite{Mullahy:1986} there is
increased interest in zero-augmented models that address this issue by a second
model component capturing zero counts. An overview of count data models in
econometrics, including  hurdle and zero-inflated models, is provided in
\cite{Cameron+Trivedi:2013}.

In \proglang{R} \citep{R}, GLMs are provided by the model fitting functions
\fct{glm} in the \pkg{stats} package and \fct{glm.nb} in the \pkg{MASS} package
\citep[][Chapter~7.4]{Venables+Ripley:2002} along with associated methods for
diagnostics and inference. The manuscript that this document is based on
\citep{Zeileis+Kleiber+Jackman:2008} then introduced hurdle and zero-inflated
count models in the functions \fct{hurdle} and \fct{zeroinfl} in the \pkg{pscl}
package \citep{Jackman:2015}. Of course, much more software could be discussed
here, including (but not limited to) generalized additive models for count data
as available in the \proglang{R} packages \pkg{mgcv} \cite{Wood:2006},
\pkg{gamlss} \citep{Stasinopoulos+Rigby:2007}, or \pkg{VGAM} \citep{Yee:2009}.


%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{Models and software} \label{sec:models}

The basic Poisson regression model for count data is a special case of the GLM
framework \cite{McCullagh+Nelder:1989}. It describes the dependence of a count
response variable $y_i$ ($i = 1, \dots, n$) by assuming a Poisson distribution
$y_i \sim \mathrm{Pois}(\mu_i)$. The dependence of the conditional mean
$\E[y_i \, | \, x_i] = \mu_i$ on the regressors $x_i$ is then specified via a
log link and a linear predictor
%
\begin{equation} \label{eq:mean}
\log(\mu_i) \quad = \quad x_i^\top \beta,
\end{equation}
%
where the regression coefficients $\beta$ are estimated by maximum likelihood
(ML) using the iterative weighted least squares (IWLS) algorithm.

\begin{leftbar}
Note that around the \verb|{equation}| above there should be no spaces (avoided
in the {\LaTeX} code by \verb|%| lines) so that ``normal'' spacing is used and
not a new paragraph started.
\end{leftbar}

\proglang{R} provides a very flexible implementation of the general GLM
framework in the function \fct{glm} \citep{Chambers+Hastie:1992} in the
\pkg{stats} package. Its most important arguments are
\begin{Code}
glm(formula, data, subset, na.action, weights, offset,
  family = gaussian, start = NULL, control = glm.control(...),
  model = TRUE, y = TRUE, x = FALSE, ...)
\end{Code}
where \code{formula} plus \code{data} is the now standard way of specifying
regression relationships in \proglang{R}/\proglang{S} introduced in
\cite{Chambers+Hastie:1992}. The remaining arguments in the first line
(\code{subset}, \code{na.action}, \code{weights}, and \code{offset}) are also
standard  for setting up formula-based regression models in
\proglang{R}/\proglang{S}. The arguments in the second line control aspects
specific to GLMs while the arguments in the last line specify which components
are returned in the fitted model object (of class \class{glm} which inherits
from \class{lm}). For further arguments to \fct{glm} (including alternative
specifications of starting values) see \code{?glm}. For estimating a Poisson
model \code{family = poisson} has to be specified.

\begin{leftbar}
As the synopsis above is a code listing that is not meant to be executed,
one can use either the dedicated \verb|{Code}| environment or a simple
\verb|{verbatim}| environment for this. Again, spaces before and after should be
avoided.

Finally, there might be a reference to a \verb|{table}| such as
Table~\ref{tab:overview}. Usually, these are placed at the top of the page
(\verb|[t!]|), centered (\verb|\centering|), with a caption below the table,
column headers and captions in sentence style, and if possible avoiding vertical
lines.
\end{leftbar}




%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

For a simple illustration of basic Poisson and NB count regression the
\code{quine} data from the \pkg{MASS} package is used. This provides the number
of \code{Days} that children were absent from school in Australia in a
particular year, along with several covariates that can be employed as regressors.
The data can be loaded by
%
<<data>>=
data("quine", package = "MASS")
@
%
and a basic frequency distribution of the response variable is displayed in
Figure~\ref{fig:quine}.

\begin{leftbar}
For code input and output, the style files provide dedicated environments.
Either the ``agnostic'' \verb|{CodeInput}| and \verb|{CodeOutput}| can be used
or, equivalently, the environments \verb|{Sinput}| and \verb|{Soutput}| as
produced by \fct{Sweave} or \pkg{knitr} when using the \code{render_sweave()}
hook. Please make sure that all code is properly spaced, e.g., using
\code{y = a + b * x} and \emph{not} \code{y=a+b*x}. Moreover, code input should
use ``the usual'' command prompt in the respective software system. For
\proglang{R} code, the prompt \code{"R> "} should be used with \code{"+  "} as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {\LaTeX} text instead. Finally, empty lines
before and after code input/output should be avoided (see above).
\end{leftbar}

\begin{figure}[t!]
\centering
<<visualization, echo=FALSE, fig=TRUE, height=5.2, width=7>>=
par(mar = c(4, 4, 1, 1))
plot(table(quine$Days), xlab = "Days", ylab = "Frequency", axes = FALSE)
axis(2)
axis(1, at = 0:16 * 5, labels = FALSE)
axis(1, at = 0:8 * 10)
box()
@
\caption{\label{fig:quine} Frequency distribution for number of days absent
from school.}
\end{figure}

As a first model for the \code{quine} data, we fit the basic Poisson regression
model. (Note that JSS prefers when the second line of code is indented by two
spaces.)
%
<<poisson>>=
m_pois <- glm(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine,
  family = poisson)
@
%
To account for potential overdispersion we also consider a negative binomial
GLM.
%
<<negbin>>=
library("MASS")
m_nbin <- glm.nb(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine)
@
%
In a comparison with the BIC the latter model is clearly preferred.
%
<<comparison>>=
BIC(m_pois, m_nbin)
@
%
Hence, the full summary of that model is shown below.
%
<<summary>>=
summary(m_nbin)
@



%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}


%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~\Sexpr{paste(R.Version()[6:7], collapse = ".")} with the
\pkg{MASS}~\Sexpr{packageVersion("MASS")} package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

\begin{leftbar}
All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).
\end{leftbar}


%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{references}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
