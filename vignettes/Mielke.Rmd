---
title: "Sample Size for Multiple Hypothesis Testing in Biosimilar Development"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sample Size for Multiple Hypothesis Testing in Biosimilar Development}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\VignetteEncoding{UTF-8}
bibliography: '`r system.file("references.bib", package="SimTOST")`'
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
require(kableExtra)
```

We here reproduce the examples of @mielke_sample_2018. In these examples, the minimal sample size is estimated to give at least 80\% power for the rejection of $k$ out of $m$ tests at a one-sided significance level of $\alpha = 0.05$ in a parallel groups design. It is assumed that the sample size, the true difference between T and R and the standard deviation of the tests is equal in each test.

# Example 1
In the first example, we have $k=m=5$, $\sigma = 0.3$ and $\rho = 0$. We can estimate the sample size using the functions provided by @mielke_sample_2018: 

```{r, eval = FALSE}
library(SimTOST)

# Calculate required sample size for 80 % power 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0, sigma = 0.3, 
         true.diff =  log(1.05), equi.tol = log(1.25), design = "parallel", 
         alpha = 0.05, adjust = "no", seed = 1234, nsim = 10000)
```
For 80\% power, 68 subjects per sequence (136 in total) would have been required. We can conduct the same analysis using `calopt`:

```{r, eval = FALSE}
calopt(power = 0.8, # target power
       alpha = 0.05,
       mu_list = list("R" = rep(log(1.00), 5),
                      "T" = rep(log(1.05), 5)),
       sigma_list = list("R" = rep(0.3, 5),
                         "T" = rep(0.3, 5)),
       lequi.tol = rep(log(0.80), 5),
       uequi.tol = rep(log(1.25), 5),
       dtype="parallel",
       ctype = "DOM", 
       lognorm = FALSE,
       adjust = "no",
       ncores = 1,
       nsim = 10000,
       seed = 1234)
```     

# Example 2
In the second example, we have $k=m=5$, $\sigma = 0.3$ and $\rho = 0.8$. We can estimate the sample size using the functions provided by @mielke_sample_2018: 

```{r, eval = FALSE}
# Required sample size for 5 out of 5 tests with high correlation (rho=0.8)
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0.8, sigma = 0.3, 
         true.diff =  log(1.05), equi.tol = log(1.25), design = "parallel", 
         alpha = 0.05, adjust = "no", seed = 1234, nsim = 10000)
```
For 80\% power, 52 subjects per sequence (104 in total) would have been required. We can conduct the same analysis using `calopt`:

```{r, eval = FALSE}
# Same example, but high correlation
calopt(power = 0.8, # target power
       alpha = 0.05,
       mu_list = list("R" = rep(1.00, 5),
                      "T" = rep(1.05, 5)),
       sigma_list = list("R" = rep(0.3, 5),
                         "T" = rep(0.3, 5)),
       rho = 0.8, # high correlation between the endpoints (rho=0.8)
       lequi.tol = rep(0.8, 5),
       uequi.tol = rep(1.25, 5),
       dtype="parallel",
       ctype = "ROM", 
       lognorm = TRUE,
       adjust = "no",
       ncores = 1,
       k=5,
       nsim = 10000,
       seed = 1234)
```

# Example 3
In the Zarzio example, we have the following:

```{r, eval = FALSE}
# Calculate the standard deviation and the mean using the 
# reported confidence intervals
sigma <- c(sqrt(40)*(log(0.8884)-log(0.8249))/qt(0.95, df=40-2), 
           sqrt(26)*(log(0.9882)-log(0.9576))/qt(0.95, df=26-2), 
           sqrt(28)*(log(0.8661)-log(0.7863))/qt(0.95, df=28-2), 
           sqrt(28)*(log(0.9591)-log(0.8873))/qt(0.95, df=28-2), 
           sqrt(24)*(log(0.885)-log(0.8155))/qt(0.95, df=24-2)
           )

mu.ratio <- c(88.84, 98.82, 86.61, 95.91, 88.5)/100 
mu <- log(mu.ratio)

# Required sample size for all tests to be successful 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05, 
         nsim = 10000)
```
We find that 47 subjects per sequence are needed, and thus 94 subjects per study or 470 in total.

```{r, eval = FALSE}
SimTOST::calopt(power = 0.8, # target power
       alpha = 0.05,
       mu_list = list("R" = c(log(1), log(1), log(1), log(1), log(1)),
                      "T" = c(log(0.8884), log(0.9882), log(0.8661), log(0.9591), log(0.8850))),
       sigma_list = list("R" = sigma,
                         "T" = sigma),
       lequi.tol = rep(log(0.80), 5),
       uequi.tol = rep(log(1.25), 5),
       dtype="2x2",
       ctype = "DOM", 
       lognorm = FALSE,
       adjust = "no",
       ncores = 1,
       nsim = 10000,
       seed = 1234)
```

# Example 4

In the Zarzio example, the required sample size to demonstrate equivalence for 3 out of 5 tests is as follows:

```{r, eval = FALSE}
# No adjustment
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "no", nsim = 10000)

# k-adjustment 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "k", nsim = 10000)

# Bonferroni adjustment 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "bon", nsim = 10000)
```
Without any adjustment, we find 18 subjects per study (hence 90 for the complete trial). When adopting k-adjustment, we find 22 subjects per study (hence 110 in total). Finally, when adopting Bonferroni adjustment we find 34 subjects per study (and thus 170 in total).


# References
