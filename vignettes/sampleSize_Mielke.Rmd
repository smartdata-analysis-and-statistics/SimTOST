---
title: "Sample Size for Multiple Hypothesis Testing in Biosimilar Development"
author: "Thomas Debray"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    fig_caption: yes
    fig_width: 9
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Sample Size for Multiple Hypothesis Testing in Biosimilar Development}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: 'references.bib'
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = "#>", collapse = TRUE)
options(rmarkdown.html_vignette.check_title = FALSE) #title of doc does not match vignette title
doc.cache <- T #for cran; change to F
```

We here reproduce the examples of @mielke_sample_2018. As a first step, we load the R package.

```{r, echo = T, message=F}
library(SimTOST)
```



# Multiple Independent Co-Primary Endpoints
The first example assumes a ratio of 1.05 between the effect sizes of the test and reference products. @mielke_sample_2018 conducts a difference-of-means test on the log scale, with $\delta = \log(1.05)$. It is assumed that the standard deviation of the log-transformed response variable is $\sigma = 0.3$, and that all tests are independent ($\rho = 0$). Below, we estimate the sample size to demonstrate that the test and reference product are equivalent with respect to all $m=5$ endpoints.

```{r, eval = TRUE}
# Calculate required sample size for 80 % power 
ssMielke <- sampleSize_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0, 
                              sigma = 0.3, true.diff =  log(1.05), 
                              equi.tol = log(1.25), design = "parallel", 
                              alpha = 0.05, adjust = "no", seed = 1234, 
                              nsim = 10000)
ssMielke
```
For 80\% power, `r ssMielke["SS"]` subjects per sequence (`r ssMielke["SS"] * 2` in total) would have been required. 

We can perform the same sample size calculation using `sampleSize`, assuming that effect sizes are normally distributed on the log scale. We use a difference-of-means test  (`ctype = "DOM"`) with the specified values for `mu_list` and `sigma_list` (`lognorm = FALSE`).

```{r, eval = TRUE}
ss <- sampleSize(power = 0.8, alpha = 0.05,
                 mu_list = list("R" = rep(log(1.00), 5),
                                "T" = rep(log(1.05), 5)),
                 sigma_list = list("R" = rep(0.3, 5),
                                   "T" = rep(0.3, 5)),
                 lequi.tol = rep(log(0.80), 5),
                 uequi.tol = rep(log(1.25), 5),
                 dtype = "parallel", ctype = "DOM", lognorm = FALSE, 
                 adjust = "no",ncores = 1, nsim = 10000, seed = 1234)
ss
```     

# Multiple Correlated Co-Primary Endpoints
In the second example, we have $k=m=5$, $\sigma = 0.3$ and $\rho = 0.8$. Again, we can estimate the sample size using the functions provided by @mielke_sample_2018: 

```{r, eval = TRUE}
ssMielke <- sampleSize_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0.8, 
                              sigma = 0.3, true.diff =  log(1.05), 
                              equi.tol = log(1.25), design = "parallel", 
                              alpha = 0.05, adjust = "no", seed = 1234, 
                              nsim = 10000)
ssMielke
```
For 80\% power, `r ssMielke["SS"]` subjects per sequence (`r ssMielke["SS"] * 2` in total) would have been required. 

We can perform the same analysis using [sampleSize()](../man/sampleSize.html). In this case, we provide estimates for $\mu$ and $\sigma$ on the original scale, assuming they follow a normal distribution on the log scale (`lognorm = TRUE`). Instead of testing the difference of log-transformed means, we now test the ratio of the (untransformed) means.

```{r, eval = TRUE}
ss <- sampleSize(power = 0.8, alpha = 0.05,
                 mu_list = list("R" = rep(1.00, 5),
                                "T" = rep(1.05, 5)),
                 sigma_list = list("R" = rep(0.3, 5),
                                   "T" = rep(0.3, 5)),
                 rho = 0.8, # high correlation between the endpoints
                 lequi.tol = rep(0.8, 5),
                 uequi.tol = rep(1.25, 5),
                 dtype = "parallel", ctype = "ROM", lognorm = TRUE, 
                 adjust = "no", ncores = 1, k = 5, nsim = 10000, seed = 1234)
ss
```

# Example 3
In the Zarzio example, we have the following:

```{r, eval = FALSE}
# Calculate the standard deviation and the mean using the 
# reported confidence intervals
sigma <- c(sqrt(40)*(log(0.8884)-log(0.8249))/qt(0.95, df=40-2), 
           sqrt(26)*(log(0.9882)-log(0.9576))/qt(0.95, df=26-2), 
           sqrt(28)*(log(0.8661)-log(0.7863))/qt(0.95, df=28-2), 
           sqrt(28)*(log(0.9591)-log(0.8873))/qt(0.95, df=28-2), 
           sqrt(24)*(log(0.885)-log(0.8155))/qt(0.95, df=24-2)
           )

mu.ratio <- c(88.84, 98.82, 86.61, 95.91, 88.5)/100 
mu <- log(mu.ratio)

# Required sample size for all tests to be successful 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 5, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05, 
         nsim = 10000)
```
We find that 47 subjects per sequence are needed, and thus 94 subjects per study or 470 in total.

```{r, eval = FALSE}
simsamplesize::calopt(power = 0.8, # target power
       alpha = 0.05,
       mu_list = list("R" = c(log(1), log(1), log(1), log(1), log(1)),
                      "T" = c(log(0.8884), log(0.9882), log(0.8661), log(0.9591), log(0.8850))),
       sigma_list = list("R" = sigma,
                         "T" = sigma),
       lequi.tol = rep(log(0.80), 5),
       uequi.tol = rep(log(1.25), 5),
       dtype="2x2",
       ctype = "DOM", 
       lognorm = FALSE,
       adjust = "no",
       ncores = 1,
       nsim = 10000,
       seed = 1234)
```

# Example 4

In the Zarzio example, the required sample size to demonstrate equivalence for 3 out of 5 tests is as follows:

```{r, eval = FALSE}
# No adjustment
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "no", nsim = 10000)

# k-adjustment 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "k", nsim = 10000)

# Bonferroni adjustment 
N_Mielke(power = 0.8, Nmax = 1000, m = 5, k = 3, rho = 0, sigma = sigma, 
         true.diff = mu, equi.tol = log(1.25), design = "22co", alpha = 0.05,
         adjust = "bon", nsim = 10000)
```
Without any adjustment, we find 18 subjects per study (hence 90 for the complete trial). When adopting k-adjustment, we find 22 subjects per study (hence 110 in total). Finally, when adopting Bonferroni adjustment we find 34 subjects per study (and thus 170 in total).


# References
