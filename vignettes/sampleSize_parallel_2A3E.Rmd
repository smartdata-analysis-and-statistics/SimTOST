---
title: "Bioequivalence Tests for Parallel Trial Designs: 2 Arms, 3 Endpoints"
author: "Thomas Debray"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    fig_caption: yes
    fig_width: 9
    fig_height: 6
vignette: >
  %\VignetteIndexEntry{Bioequivalence Tests for Parallel Trial Designs: 2 Arms, 3 Endpoints}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: 'references.bib'
link-citations: yes
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = "#>", collapse = TRUE)
options(rmarkdown.html_vignette.check_title = FALSE) #title of doc does not match vignette title
doc.cache <- T #for cran; change to F
```

# Introduction

In many studies, it is necessary to evaluate equivalence across multiple primary variables. For instance, the European Medicines Agency (EMA) recommends demonstrating equivalence for both **Area Under the Curve** (AUC) and **maximum concentration** (Cmax) when assessing pharmacokinetic properties.

When multiple primary endpoints are involved, a decision must be made on the desired criteria for equivalence:

* Equivalence for All Primary Endpoints
  * This is the most common setting and is often referred to as having *multiple co-primary endpoints*.
  * Equivalence must be demonstrated for **all** endpoints to conclude overall equivalence.
* Equivalence for At Least One Primary Endpoint
  * Known as having *multiple primary endpoints*.
  * Equivalence is required for **at least one** endpoint to meet the study's objectives.

This vignette presents advanced techniques for calculating sample size in parallel trial designs involving three treatment arms and two endpoints. Specifically, it focuses on bioequivalence testing between a new treatment (SB2) and a reference drug (Remicade) administered in two distinct locations (EU_Remicade and USA_Remicade).

As an illustrative example, we consider published data from the phase-1 trial [NCT01922336](https://clinicaltrials.gov/study/NCT01922336#study-overview). This trial assessed the pharmacokinetics of SB2 compared to its EU-sourced reference product. The following outcomes were reported following a single dose of SB2 or its EU reference product [@shin_randomized_2015]:

```{r, echo=FALSE}
data <- data.frame("PK measure" = c("AUCinf ($\\mu$g*h/mL)","AUClast ($\\mu$g*h/mL)","Cmax ($\\mu$g/mL)"),
                   "SB2" = c("38,703 $\\pm$ 11,114", "36,862 $\\pm$ 9133", "127.0 $\\pm$ 16.9"), 
                   "EU-INF" = c("39,360  $\\pm$ 12,332", "37,022 $\\pm$ 9398", "126.2 $\\pm$ 17.9"))

kableExtra::kable_styling(kableExtra::kable(data, 
                                            col.names = c("PK measure", "SB2", "Remicade (EU)"),
                                            caption = "Primary PK measures between test and reference product. Data represent arithmetic mean +- standard deviation."),
                          bootstrap_options = "striped")
```

In the sections below, we explore various strategies for determining the sample size required for a parallel trial to demonstrate equivalence across the three co-primary endpoints. These strategies are based on the Ratio of Means (ROM) approach, with equivalence bounds set between 80\% and 125\%.

# Independent Testing of Co-Primary Endpoints
A conservative approach to sample size calculation involves testing each pharmacokinetic (PK) measure independently. This method assumes that the endpoints are uncorrelated and that equivalence must be demonstrated for each endpoint separately. Consequently, the overall sample size required for the trial is the sum of the sample sizes for each PK measure.

```{r}
library(SimTOST)

# Sample size calculation for AUCinf
(sim_AUCinf <- sampleSize(
  power = 0.9,                                # Target power
  alpha = 0.05,                               # Significance level
  arm_names = c("SB2", "EU_Remicade"),        # Names of trial arms
  list_comparator = list("EMA" = c("SB2", "EU_Remicade")),  # Comparator configuration
  mu_list = list("SB2" = 38703, "EU_Remicade" = 39360),     # Mean values
  sigma_list = list("SB2" = 11114, "EU_Remicade" = 12332),  # Standard deviation values
  list_lequi.tol = list("EMA" = 0.80),        # Lower equivalence margin
  list_uequi.tol = list("EMA" = 1.25),        # Upper equivalence margin
  ncores = 1,                                 # Number of computation cores
  nsim = 1000                                 # Number of stochastic simulations
))

# Sample size calculation for AUClast
(sim_AUClast <- sampleSize(
  power = 0.9,                                # Target power
  alpha = 0.05,                               # Significance level
  arm_names = c("SB2", "EU_Remicade"),        # Names of trial arms
  list_comparator = list("EMA" = c("SB2", "EU_Remicade")),  # Comparator configuration
  mu_list = list("SB2" = 36862, "EU_Remicade" = 37022),     # Mean values
  sigma_list = list("SB2" = 9133, "EU_Remicade" = 9398),    # Standard deviation values
  list_lequi.tol = list("EMA" = 0.80),        # Lower equivalence margin
  list_uequi.tol = list("EMA" = 1.25),        # Upper equivalence margin
  ncores = 1,                                 # Number of computation cores
  nsim = 1000                                 # Number of stochastic simulations
))


# Sample size calculation for Cmax
(sim_Cmax <- sampleSize(
  power = 0.9,                                # Target power
  alpha = 0.05,                               # Significance level
  arm_names = c("SB2", "EU_Remicade"),        # Names of trial arms
  list_comparator = list("EMA" = c("SB2", "EU_Remicade")),  # Comparator configuration
  mu_list = list("SB2" = 127.0, "EU_Remicade" = 126.2),     # Mean values
  sigma_list = list("SB2" = 16.9, "EU_Remicade" = 17.9),    # Standard deviation values
  list_lequi.tol = list("EMA" = 0.80),        # Lower equivalence margin
  list_uequi.tol = list("EMA" = 1.25),        # Upper equivalence margin
  ncores = 1,                                 # Number of computation cores
  nsim = 1000                                 # Number of stochastic simulations
))
```

If we were to test each PK measure independently, we would find a total sample size of `r sim_AUCinf$response$n_total` for AUCinf, `r sim_AUClast$response$n_total` for AUClast, and `r sim_Cmax$response$n_total` for Cmax. This means that we would have to enroll `r sim_AUCinf$response$n_total` + `r sim_AUClast$response$n_total` + `r sim_Cmax$response$n_total` = `r sim_AUCinf$response$n_total + sim_AUClast$response$n_total + sim_Cmax$response$n_total` patients in order to reject $H_0$ at a significance level of 5\%. For context, the original trial was a randomized, single-blind, three-arm, parallel-group study conducted in 159 healthy subjects, slightly more than the `r sim_AUCinf$response$n_total + sim_AUClast$response$n_total + sim_Cmax$response$n_total` patients estimated as necessary. This suggests that the original trial had a small buffer above the calculated sample size requirements.

# Simultaneous Testing of Independent Co-Primary Endpoints
This approach focuses on simultaneous testing of pharmacokinetic (PK) measures while assuming independence between endpoints. Unlike the previous approach, which evaluated each PK measure independently, this method integrates comparisons across multiple endpoints, accounting for correlations (or lack thereof) between them. By doing so, it enables simultaneous testing for equivalence without inflating the overall Type I error rate.

## Key Assumptions
In the calculations below, the following assumptions are made:

* Hypothesis Testing Approach: Ratio of Means (ROM)
* Design: A parallel trial design
* Distribution: PK measures follow a log-normal distribution.
* Standard Deviation: All treatments share a  common standard deviation for each endpoint
* Multiplicity: No multiplicity adjustments are applied.
* Equivalence Criterion: Equivalence is required for all $k=m=3$ endpoints.
* Independence: All endpoints are assumed to be uncorrelated, specified by setting the correlation parameter to $\rho=0$.

## Input Data

The arithmetic means and standard deviations for each endpoint and treatment arm are defined as follows:
```{r}
mu_list <- list(
  SB2 = c(AUCinf = 38703, AUClast = 36862, Cmax = 127.0),
  EUREF = c(AUCinf = 39360, AUClast = 37022, Cmax = 126.2)
)

sigma_list <- list(
  SB2 = c(AUCinf = 11114, AUClast = 9133, Cmax = 16.9),
  EUREF = c(AUCinf = 12332, AUClast = 9398, Cmax = 17.9)
)
```

## Equivalence Boundaries
Since we are comparing multiple co-primary endpoints, it is essential to define the lower and upper equivalence boundaries for each endpoint. These boundaries determine the acceptable range for the Ratio of Means (ROM) within which equivalence is established.

For simplicity, the same equivalence boundaries are applied to all endpoints:

```{r}
# Equivalent boundaries
list_comparator <- list("Comparison" = c("SB2","EUREF"))
list_lequi.tol <- list("Comparison" = c(AUCinf = 0.8, AUClast = 0.8, Cmax = 0.8))
list_uequi.tol <- list("Comparison" = c(AUCinf = 1.25, AUClast = 1.25, Cmax = 1.25))
```

By default, it is required that all $k=m$ co-primary endpoints have to be equivalent:

## Computing Sample Size

```{r}
(N_ss <- sampleSize(power = 0.9, # target power
                    alpha = 0.05,
                    mu_list = mu_list,
                    sigma_list = sigma_list,
                    list_comparator = list_comparator,
                    list_lequi.tol = list_lequi.tol,
                    list_uequi.tol = list_uequi.tol,
                    dtype = "parallel",
                    ctype = "ROM",
                    vareq = TRUE,
                    lognorm = TRUE,
                    ncores = 1,
                    nsim = 1000,
                    seed = 1234))
```

We can inspect more detailed sample size requirements as follows:

```{r}
N_ss$response
```

# Simultaneous Testing of Correlated Co-Primary Endpoints

Incorporating the correlation among endpoints into power and sample size calculations for co-primary continuous endpoints offers significant advantages. [@sozu_sample_2015] Without accounting for correlation, adding more endpoints typically reduces the power. However, by including positive correlations in the calculations, power can be increased, and required sample sizes may be reduced.

For this analysis, we proceed with the same values used previously but now assume that a correlation exists between endpoints. Specifically, we set $\rho = 0.6$, assuming a common correlation across all endpoints.

If correlations differ between endpoints, they can be specified individually using a correlation matrix (`cor_mat`), allowing for greater flexibility in the analysis.

```{r}
(N_mult_corr <- sampleSize(power = 0.9, # target power
                           alpha = 0.05,
                           mu_list = mu_list,
                           sigma_list = sigma_list,
                           list_comparator = list_comparator,
                           list_lequi.tol = list_lequi.tol,
                           list_uequi.tol = list_uequi.tol,
                           rho = 0.6,
                           dtype = "parallel",
                           ctype = "ROM",
                           vareq = TRUE,
                           lognorm = TRUE,
                           ncores = 1,
                           nsim = 1000,
                           seed = 1234))
```

Referring to the output above, the required sample size for this setting is `r N_mult_corr$response$n_total`. This is `r N_ss$response$n_total - N_mult_corr$response$n_total` fewer patients than the scenario where the endpoints are assumed to be uncorrelated.

# Simultaneous Testing of Independent Primary Endpoints
Consider now we are interested in demonstrating equivalence for at least $k=1$ of the $m=3$ primary endpoints. Unlike the previous cases, where equivalence was required for all endpoints, this setting necessitates an adjustment for multiplicity to control the family-wise error rate.

```{r}
(N_mp_bon <- sampleSize(
  power = 0.9,               # Target power
  alpha = 0.05,              # Significance level
  mu_list = mu_list,         # List of means
  sigma_list = sigma_list,   # List of standard deviations
  list_comparator = list_comparator,  # Comparator configurations
  list_lequi.tol = list_lequi.tol,    # Lower equivalence boundaries
  list_uequi.tol = list_uequi.tol,    # Upper equivalence boundaries
  rho = 0.6,                 # Correlation between endpoints
  dtype = "parallel",        # Trial design type
  ctype = "ROM",             # Test type (Ratio of Means)
  vareq = TRUE,              # Assume equal variances
  lognorm = TRUE,            # Log-normal distribution assumption
  k = 1,                     # Reject at least one null hypothesis
  adjust = "bon",            # Bonferroni adjustment method
  ncores = 1,                # Number of cores for computation
  nsim = 1000,               # Number of stochastic simulations
  seed = 1234                # Random seed for reproducibility
))
```
As mentioned in [the Introduction](../articles/intopkg.html), the Bonferroni correction is often overly conservative, especially in scenarios with correlated tests. A less restrictive alternative is the *k*-adjustment, which specifically accounts for the number of tests and the number of endpoints required for equivalence.

```{r}
(N_mp_k <- sampleSize(
  power = 0.9,               # Target power
  alpha = 0.05,              # Significance level
  mu_list = mu_list,         # List of means
  sigma_list = sigma_list,   # List of standard deviations
  list_comparator = list_comparator,  # Comparator configurations
  list_lequi.tol = list_lequi.tol,    # Lower equivalence boundaries
  list_uequi.tol = list_uequi.tol,    # Upper equivalence boundaries
  rho = 0.6,                 # Correlation between endpoints
  dtype = "parallel",        # Trial design type
  ctype = "ROM",             # Test type (Ratio of Means)
  vareq = TRUE,              # Assume equal variances
  lognorm = TRUE,            # Log-normal distribution assumption
  k = 1,                     # Reject at least one null hypothesis
  adjust = "k",              # Adjustment method
  ncores = 1,                # Number of cores for computation
  nsim = 1000,               # Number of stochastic simulations
  seed = 1234                # Random seed for reproducibility
))
```

# References
