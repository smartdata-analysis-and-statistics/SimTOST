---
title: "Validation of Crossover (2x2) Design"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Validation of Crossover (2x2) Design}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
require(kableExtra)
```

In this report we validate the results of the calop function by comparing with some examples provided in the literature about sample size calculation for a cross over design (2x2).

# Example 1 (Pass)

This is an example part of the pass documentation, where it is calculated the sample size of a cross-over desing used to compare the measures of diastolic blood pressure (Y) obtained after administrating two drugs (T= treatment and R= reference)
The average diastolic pressure for the reference was $Y_r$ = 96 mmHg and it is expected that new drug decrese the measure to $Y_t$ = 92 mmHg. The within mean square error of similar studies is 324, $\sigma_w=18$.
The objective of the study is to demostrate that the measure of the new drug $Y_t$ are within the 20% of the reference drug. Therefore they use as equivalence limits [-19.2,19.2]. 
Thew want to calculate the sample size for a significance level of 0.05. According to the example they required approximately 26 subjects for a power of 90% and 20 subjects for a power of 80%
In our case, we assume that treatment and reference have the same within subject variance and include it on the sigma_list parameter

```{r, eval = FALSE}
library(simsamplesize)

calopt(power = 0.8, # target power
       alpha = 0.05,
       mu_list = list("R" = 96, "T" = 92),
       sigma_list = list("R" = 18,"T" = 18),
       lequi.tol = -19.2,
       uequi.tol = 19.2,
       dtype="2x2",
       ctype = "DOM", 
       lognorm = FALSE,
       nsim = 3000,
       seed = 1234)
```  

In this case we obtain a require of 28 subjects for a power of 90% and  20 subjects for a power of 80%.

# Example 2

We consider the Phillips (1990) study where it is required the sample size for a target power of 70%  to compare a treatment and a reference. Here it is specified set of differences between treatment that range from 0, -5, -10, 15 and a within subject standard deviation of 20. Here we consider that the mean reference ($\mu_R$) is 100 and the lower and upper equivalence limits are the 20% of $\mu_R$.


```{r, eval = FALSE}
calopt(power = 0.7, # target power
       alpha = 0.05,
       mu_list = list("R" = 100, "T" = 100),
       sigma_list = list("R" = 20,
                          "T" = 20),
       lequi.tol = -20,
       uequi.tol = 20,
       dtype="2x2",
       ctype = "DOM", 
       lognorm = FALSE,
       nsim = 3000,
       seed = 1234)
``` 
For the actual difference of 0, the author reports a sample size of 16, that is identical we obtain with calop function.

Additionally the lower and upper equivalence we

# Example 3 
Below we will calculate the sample size for the study reported by Machin et al. (1997), in which the reference mean is 35.03 and treatment mean is 35.03 where the  within standard deviation is set to the 40% of the reference mean. The limits are -20 and 20.

```{r, eval = FALSE}
calopt(power = 0.8, # target power
       alpha = 0.1,
       mu_list = list("R" = 35.03, "T" = 35.03),
       sigma_list = list("R" = 40,  "T" = 40),
       lequi.tol = -20,
       uequi.tol = 20,
       dtype="2x2",
       ctype = "DOM", 
       lognorm = FALSE,
       nsim = 3000,
       seed = 1234)
``` 
According the study there are required 54 patients and our procedure returns also 54 patients. 



# Crossover Design 

In this example we use the same parameters as in the initial example. However the study design is 2x2 crossover design. In a crossover design, each patient receive both treatments during the trial, serving as their own matched control. This design is preferred over the parallel design as it may require fewer patients to achieve the same level of statistical power.In this case we need only to change `dtype` argument to be "2x2". 


```{r, eval=FALSE}
N_ss <- calopt(mu_list = list("Test" = 96, "Control" = 92),
               sigma_list = list("Test" = 18, "Control" = 18),
               lequi.tol = 0.8, 
               uequi.tol = 1.25, # bioequivalence limits
               dtype = "2x2",
               lognorm = TRUE, # distribution assumption
               ctype = "ROM", # comparison type
               vareq = TRUE, # variance assumption
               power = 0.9, # target power
               alpha = 0.05,
               ncores = 1,
               nsim = 50,
               seed = 1234)

N_ss$response
```

Compared to the result obtained using parallel design, the trial incorporates Crossover design requires fewer sample size. This is understandable as in this design, a subject can receives different treatment or cross over from one to another treatment during the course of the trial.

To simplify the calculation procedure for sample size in crossover design, it's common practice to assume that the between-subject variance of the crossover design is approximately half of the total variance in the parallel design. Implicitely assuming that the correlation is 0.5 between two measures in the same subject (Julious pp.1932). This allows for a more straightforward estimation process, however the strict calculation of sample size for this design requires the use of  both within and between variances, which function is still under development in our package.

Now, we want to compare the result with the `PowerTOST`'s result.

```{r, eval = FALSE}
# set design argument design to be 2x2

N_pt <- PowerTOST::sampleN.TOST(logscale = TRUE,
                                theta0 = 96/92,
                                theta1 = 0.8,
                                theta2 = 1.25,
                                targetpower = 0.9,
                                CV = 18/92, 
                                design = "2x2",
                                print = FALSE)
kable(N_pt)
```


```{r, eval = FALSE}
#Using `PowerTOST`, the required sample size is `r N_pt["Sample size"]`. In this case, the required sample size  is smaller than the result from `simsamplesize`. Our algorithm selects the sample size that achieve in average at least the target power 90\%, in this case a sample size of `r N_ss$response[["n_total"]]` with a power of  `r N_ss$response[["power"]]`. But by inspecting the iteration table, we observe that with a sample size of 22, we can obtain a target power inside the confidence interval of the calculated power.
```




```{r, eval = FALSE}
 N_ss[["table.iter"]]
```


```{r, eval = FALSE}
# Using `PowerTOST`, the required sample size is `r N_pt["Sample size"]`. In this case, the required sample size  is equal to the result from `simsamplesize`.
```







